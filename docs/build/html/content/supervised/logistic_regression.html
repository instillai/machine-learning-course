

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Logistic Regression &mdash; Machine-Learning-Course 1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Naive Bayes Classification" href="bayes.html" />
    <link rel="prev" title="Regularization" href="../overview/regularization.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/pythonml.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Table of Content</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../authorship/author.html">Authorship</a></li>
</ul>
<p class="caption"><span class="caption-text">Foreword</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intro/intro.html">Introduction</a></li>
</ul>
<p class="caption"><span class="caption-text">Core Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview/crossvalidation.html">Cross-Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/linear-regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/overfitting.html">Overfitting and Underfitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/regularization.html">Regularization</a></li>
</ul>
<p class="caption"><span class="caption-text">Supervised Learning</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Logistic Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#when-to-use">When to Use</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-does-it-work">How does it work?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#multinomial-logistic-regression">Multinomial Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="#code">Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="#motivation">Motivation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#conclusion">Conclusion</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="bayes.html">Naive Bayes Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="decisiontrees.html">Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="knn.html">k-Nearest Neighbors</a></li>
<li class="toctree-l1"><a class="reference internal" href="linear_SVM.html">Linear Support Vector Machines</a></li>
</ul>
<p class="caption"><span class="caption-text">Unsupervised Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../unsupervised/clustering.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unsupervised/pca.html">Principal Component Analysis</a></li>
</ul>
<p class="caption"><span class="caption-text">Deep Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/mlp.html">Multi-layer Perceptron</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/cnn.html">Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/autoencoder.html">Autoencoders</a></li>
</ul>
<p class="caption"><span class="caption-text">Document Credentials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../credentials/LICENSE.html">LICENSE</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Machine-Learning-Course</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
      <li>Logistic Regression</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com///blob/content/supervised/logistic_regression.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="logistic-regression">
<h1>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><a class="reference internal" href="#introduction" id="id1">Introduction</a></li>
<li><a class="reference internal" href="#when-to-use" id="id2">When to Use</a></li>
<li><a class="reference internal" href="#how-does-it-work" id="id3">How does it work?</a></li>
<li><a class="reference internal" href="#multinomial-logistic-regression" id="id4">Multinomial Logistic Regression</a></li>
<li><a class="reference internal" href="#code" id="id5">Code</a></li>
<li><a class="reference internal" href="#motivation" id="id6">Motivation</a></li>
<li><a class="reference internal" href="#conclusion" id="id7">Conclusion</a></li>
<li><a class="reference internal" href="#references" id="id8">References</a></li>
</ul>
</div>
<div class="section" id="introduction">
<h2><a class="toc-backref" href="#id1">Introduction</a><a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Logistic regression is a method for binary classification.  It works to divide
points in a dataset into two distinct classes, or categories.
For simplicity, let’s call them class A and class B.
The model will give us the probability that a given point belongs in category B.
If it is low (lower than 50%), then we classify it in category A.
Otherwise, it falls in class B.
It’s also important to note that logistic regression is better for this purpose
than linear regression with a threshold
because the threshold would have to be manually set, which is not feasible.
Logistic regression will instead create a sort of S-curve
(using the sigmoid function) which will also help show certainty, since the
output from logistic regression is not just a one or zero.
Here is the standard logistic function, note that the output is always between
0 and 1, but never reaches either of those values.</p>
<div class="figure">
<a class="reference internal image-reference" href="../../_images/WikiLogistic.svg.png"><img alt="Logistic" src="../../_images/WikiLogistic.svg.png" style="width: 320.0px; height: 213.0px;" /></a>
</div>
<p>Ref: <a class="reference external" href="https://en.wikipedia.org/wiki/Logistic_regression">https://en.wikipedia.org/wiki/Logistic_regression</a></p>
</div>
<div class="section" id="when-to-use">
<h2><a class="toc-backref" href="#id2">When to Use</a><a class="headerlink" href="#when-to-use" title="Permalink to this headline">¶</a></h2>
<p>Logistic regression is great for situations where you need to classify between two categories.
Some good examples are accepted and rejected applicants and victory or defeat in a competition.
Here is an example table of data that would be a good candidate for logistic regression.</p>
<table border="1" class="docutils">
<colgroup>
<col width="26%" />
<col width="37%" />
<col width="37%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head" colspan="2">Studying</th>
<th class="head">Success</th>
</tr>
<tr class="row-even"><th class="head">Hours</th>
<th class="head">Focused</th>
<th class="head">Pass?</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-odd"><td>1</td>
<td>False</td>
<td>False</td>
</tr>
<tr class="row-even"><td>3</td>
<td>False</td>
<td>True</td>
</tr>
<tr class="row-odd"><td>0.5</td>
<td>True</td>
<td>False</td>
</tr>
<tr class="row-even"><td>2</td>
<td>False</td>
<td>True</td>
</tr>
</tbody>
</table>
<p>Notice that the student’s success is determined by the inputs and the value is
binary, so logistic regression will work well for this scenario.</p>
</div>
<div class="section" id="how-does-it-work">
<h2><a class="toc-backref" href="#id3">How does it work?</a><a class="headerlink" href="#how-does-it-work" title="Permalink to this headline">¶</a></h2>
<p>Logistic regression works using a linear combination of inputs, so multiple
information sources can govern the output of the model.
The parameters of the model are the weights of the various features, and
represent their relative importance to the result.
In the equation that follows, you should recognize the formula used in linear regression.
Logistic regression is, at its base, a transformation from a linear predictor
to a probability between 0 and 1.</p>
<div class="figure">
<img alt="Equation" src="../../_images/WikiLogisticEQ.svg" /></div>
<p>Ref: <a class="reference external" href="https://en.wikipedia.org/wiki/Logistic_regression">https://en.wikipedia.org/wiki/Logistic_regression</a></p>
<p>As in linear regression, the beta values are the weights and x values are the variable inputs.
This formula gives the probability that the input belongs to Class B, which
is the goal of the logistic regression model.</p>
</div>
<div class="section" id="multinomial-logistic-regression">
<h2><a class="toc-backref" href="#id4">Multinomial Logistic Regression</a><a class="headerlink" href="#multinomial-logistic-regression" title="Permalink to this headline">¶</a></h2>
<p>Until now, we’ve been discussing the situation where there are exactly
two distinct outputs, for example a pass or a fail.
But, what if there were more than two possible outputs?
What about the number classification example, where the output can be any digit from 0 to 9?</p>
<p>Well, there is a way to handle that with logistic regression.
When using the scikit-learn library, as the example code does, the facility is already there.
With scikit-learn, you can use the multinomial mode and supply any number of
classes in the training data.
You can think of the method as creating multiple models and comparing their
probabilities, but the exact <a class="reference external" href="https://en.wikipedia.org/wiki/Multinomial_logistic_regression">details</a> are beyond the scope of this course.</p>
</div>
<div class="section" id="code">
<h2><a class="toc-backref" href="#id5">Code</a><a class="headerlink" href="#code" title="Permalink to this headline">¶</a></h2>
<p>Check out the <a class="reference external" href="https://github.com/machinelearningmindset/machine-learning-course/blob/master/code/supervised/Logistic_Regression/logistic_ex1.py">example</a> for logistic regression in our repository.</p>
<p>In the example, scikit-learn and numpy are used to train a simple logistic regression model.
The model is basic, but extensible.
With logistic regression, more features could be added to the data set
seamlessly, simply as a column in the 2D arrays.</p>
<p>The code creates a 2D array representing the training input, in this case it is
1000 x 1, since there are 1000 samples and 1 feature.
These inputs are scores out of 1000.
A training output array is also created, with the classification of 1 for
pass and 0 for fail, based on a threshold.
Then, scikit-learn’s <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">LogisticRegression</a> class is used to fit a logistic
regression classifier to the data.
After that, the next step is to test for accuracy with a different data set.
So, we create another 100 random samples to test against, and predict against them using the model.</p>
</div>
<div class="section" id="motivation">
<h2><a class="toc-backref" href="#id6">Motivation</a><a class="headerlink" href="#motivation" title="Permalink to this headline">¶</a></h2>
<p>Why use logistic regression?
Logistic regression is well suited to the case of <strong>binary classification</strong>,
or classifying in 2 categories.
Logistic regression is also a relatively simple method, utilizing a weighted
sum of inputs, similar to linear regression.
Logistic regression is also useful in that it gives a continuous value,
representing the probability of a given classification being correct.
For these reasons, advocates say that logistic regression should be the
<a class="reference external" href="https://towardsdatascience.com/5-reasons-logistic-regression-should-be-the-first-thing-you-learn-when-become-a-data-scientist-fcaae46605c4">first</a> thing learned in the data science world.</p>
</div>
<div class="section" id="conclusion">
<h2><a class="toc-backref" href="#id7">Conclusion</a><a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>Logistic regression build upon linear regression by extending its use to classification.
Although it is not able to classify into more than two classes, it is still
effective in what it does, and simple to implement.
Consider logistic regression as the first thought pass/fail method.
When you just need a pass/fail probability from data, logistic regression is the simplest and likely best option.</p>
<p>Machine learning libraries make using Logistic Regression very simple.
Check out the example code in the repository and follow along.
The basic idea is to supply the training data as pairs of input and
classification, and the model will be built automatically.
As always, keep in mind the basics mentioned in the overview section of this
repository, as there is no fool-proof method for machine learning.</p>
</div>
<div class="section" id="references">
<h2><a class="toc-backref" href="#id8">References</a><a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><a class="reference external" href="https://towardsdatascience.com/logistic-regression-b0af09cdb8ad">https://towardsdatascience.com/logistic-regression-b0af09cdb8ad</a></li>
<li><a class="reference external" href="https://medium.com/datadriveninvestor/machine-learning-model-logistic-regression-5fa4ffde5773">https://medium.com/datadriveninvestor/machine-learning-model-logistic-regression-5fa4ffde5773</a></li>
<li><a class="reference external" href="https://github.com/bfortuner/ml-cheatsheet/blob/master/docs/logistic_regression.rst">https://github.com/bfortuner/ml-cheatsheet/blob/master/docs/logistic_regression.rst</a></li>
<li><a class="reference external" href="https://machinelearningmastery.com/logistic-regression-tutorial-for-machine-learning/">https://machinelearningmastery.com/logistic-regression-tutorial-for-machine-learning/</a></li>
<li><a class="reference external" href="https://towardsdatascience.com/logistic-regression-a-simplified-approach-using-python-c4bc81a87c31">https://towardsdatascience.com/logistic-regression-a-simplified-approach-using-python-c4bc81a87c31</a></li>
<li><a class="reference external" href="https://hackernoon.com/introduction-to-machine-learning-algorithms-logistic-regression-cbdd82d81a36">https://hackernoon.com/introduction-to-machine-learning-algorithms-logistic-regression-cbdd82d81a36</a></li>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Logistic_regression">https://en.wikipedia.org/wiki/Logistic_regression</a></li>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Multinomial_logistic_regression">https://en.wikipedia.org/wiki/Multinomial_logistic_regression</a></li>
<li><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</a></li>
<li><a class="reference external" href="https://towardsdatascience.com/5-reasons-logistic-regression-should-be-the-first-thing-you-learn-when-become-a-data-scientist-fcaae46605c4">https://towardsdatascience.com/5-reasons-logistic-regression-should-be-the-first-thing-you-learn-when-become-a-data-scientist-fcaae46605c4</a></li>
</ol>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="bayes.html" class="btn btn-neutral float-right" title="Naive Bayes Classification" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../overview/regularization.html" class="btn btn-neutral float-left" title="Regularization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Amirsina Torfi
      <span class="lastupdated">
        Last updated on True.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>